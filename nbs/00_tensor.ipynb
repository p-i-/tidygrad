{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class Tensor:\n",
    "    op = \"L\"\n",
    "    name: str = \"\"\n",
    "    parents: list = []\n",
    "\n",
    "    def __init__(self, data, name=\"\"):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.grad = np.zeros_like(self.data)\n",
    "\n",
    "    def add(self, other, name):\n",
    "        out = AddTensor(data=self.data + other.data, name=name)\n",
    "        out.parents = [self, other]\n",
    "        return out\n",
    "\n",
    "    def mul(self, other, name):\n",
    "        out = MulTensor(data=self.data * other.data, name=name)\n",
    "        out.parents = [self, other]\n",
    "        return out\n",
    "\n",
    "    def mmul(self, other, name):\n",
    "        out = MulTensor(data=self.data @ other.data, name=name)\n",
    "        out.parents = [self, other]\n",
    "        return out\n",
    "\n",
    "    def sum(self, name):\n",
    "        out = SumTensor(data=self.data.sum(), name=name)\n",
    "        out.parents = [self]\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        # Create a list of all parent nodes, in reverse order\n",
    "        # Start with the current node\n",
    "        visited = []\n",
    "        nodes = []\n",
    "\n",
    "        def walk(node):\n",
    "            for p in node.parents:\n",
    "                if p not in visited:\n",
    "                    visited.append(p)\n",
    "                    walk(p)\n",
    "                    nodes.append(p)\n",
    "\n",
    "        walk(self)\n",
    "        nodes.append(self)\n",
    "\n",
    "        # print(nodes)\n",
    "        self.grad = np.ones_like(self.data)\n",
    "        for n in nodes[::-1]:\n",
    "            if hasattr(n, \"_backward\"):\n",
    "                n._backward()\n",
    "\n",
    "    def __repr__(self):\n",
    "        res = f\"[{self.op or ''}] {self.name}={str(self.data)} {self.name}.grad={str(self.grad)}\"\n",
    "        if self.parents:\n",
    "            res += (\n",
    "                f\" {self.name}.parents=[\" + \",\".join([p.name for p in self.parents]) + \"]\"\n",
    "            )\n",
    "\n",
    "        return f\"Tensor({res})\"\n",
    "\n",
    "\n",
    "class AddTensor(Tensor):\n",
    "    op = \"+\"\n",
    "\n",
    "    def _backward(self):\n",
    "        self.parents[0].grad += self.grad\n",
    "        self.parents[1].grad += self.grad\n",
    "\n",
    "\n",
    "class MulTensor(Tensor):\n",
    "    op = \"*\"\n",
    "\n",
    "    def _backward(self):\n",
    "        self.parents[0].grad += self.grad * self.parents[1].data\n",
    "        self.parents[1].grad += self.grad * self.parents[0].data\n",
    "\n",
    "\n",
    "class MmulTensor(Tensor):\n",
    "    op = \"@\"\n",
    "\n",
    "    def _backward(self):\n",
    "        self.parents[0].grad += self.grad @ self.parents[1].data\n",
    "        self.parents[1].grad += self.grad @ self.parents[0].data\n",
    "\n",
    "\n",
    "class SumTensor(Tensor):\n",
    "    op = \"sum\"\n",
    "\n",
    "    def _backward(self):\n",
    "        self.parents[0].grad += self.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([+] e=5 e.grad=0 e.parents=[c,d])\n"
     ]
    }
   ],
   "source": [
    "a = Tensor(1, \"a\")\n",
    "b = Tensor(2, \"b\")\n",
    "\n",
    "c = a.add(b, \"c\")\n",
    "d = a.mul(b, \"d\")\n",
    "e = c.add(d, \"e\")\n",
    "\n",
    "\n",
    "print(e)\n",
    "\n",
    "e.grad = 1\n",
    "# e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(np.ones((10, 10)), \"a\")\n",
    "b = Tensor(np.ones((10, 10)) * 2, \"b\")\n",
    "\n",
    "c = a.mmul(b, \"c\")\n",
    "\n",
    "s = c.sum(\"s\")\n",
    "\n",
    "s.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([sum] s=2000.0 s.grad=1.0 s.parents=[c])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]]),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xl0/mambaforge/envs/torch2/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6.]], dtype=torch.float64),\n",
       " tensor([[3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.],\n",
       "         [3., 3., 3.]], dtype=torch.float64))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from torch import Tensor, tensor\n",
    "\n",
    "a = tensor(np.ones((3, 4)), requires_grad=True)\n",
    "b = tensor(np.ones((4, 3)) * 2, requires_grad=True)\n",
    "\n",
    "c = (a @ b).sum()\n",
    "\n",
    "c.backward()\n",
    "a.grad, b.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
